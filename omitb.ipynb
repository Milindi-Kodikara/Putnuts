{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Inside the heads of Putnuts\n",
    "#### An analysis of the Only Murders in the Building TV show subreddit\n",
    "\n",
    "Milindi Kodikara"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ffc24dbff90242e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 0 : : Set up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc7521a9bd0a65f2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from client import client\n",
    "import helper\n",
    "import visualiser\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce4026b269df7302",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subreddit_name = 'OnlyMurdersHulu'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5566865b12f59784",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reddit_client = client()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27fec5e5d6f2e7d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print('Username :: ', reddit_client.user.me())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc561188ad2d632",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subreddit = reddit_client.subreddit(subreddit_name)\n",
    "\n",
    "print('Subreddit :: ', subreddit)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bedec8775778c98",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_new_posts = [*subreddit.new(limit=None)] \n",
    "\n",
    "new_season_announcement_date = datetime(2023, 10, 4, 0, 0, 0)\n",
    "season_premier = datetime(2024, 8, 27, 23, 59, 59)\n",
    "\n",
    "timestamp_new_season_announcement_date = calendar.timegm(new_season_announcement_date.utctimetuple())\n",
    "timestamp_season_premier = calendar.timegm(season_premier.utctimetuple())\n",
    "\n",
    "posts = [post for post in all_new_posts if timestamp_new_season_announcement_date <= post.created_utc <= timestamp_season_premier]\n",
    "\n",
    "print('New season announcement date: ', new_season_announcement_date.strftime(\"%d/%m/%Y\"))\n",
    "print('New season announcement date timestamp: ', timestamp_new_season_announcement_date)\n",
    "\n",
    "print('Season premier: ', season_premier.strftime(\"%d/%m/%Y\"))\n",
    "print('Season premier timestamp: ', timestamp_season_premier)\n",
    "\n",
    "print(f'New posts: {len(all_new_posts)}\\nNew posts from the new season announcement leading up to season premier: {len(posts)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc48f36a14f70818",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "oliver = '#275c4d'\n",
    "mabel = '#af221d'\n",
    "charles = '#c59103'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28dfc294945e10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Ask why use Tweet Tokenizer, why not word_tokenizer\n",
    "tokeniser = TweetTokenizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "# add punctuation to stopwords list\n",
    "stop_words = stopwords.words('english') + list(string.punctuation) + ['rt', 'via', '...', 'â€¦', '\"', \"'\", '`', '-']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cb4af43c0fcaa3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unprocessed_token_lists = []\n",
    "processed_token_lists = []\n",
    "\n",
    "omitb_df = pd.DataFrame(columns=['Post', 'Num_comments', 'Author', 'UTC_Date', 'Date', 'Upvote_ratio', 'Unprocessed_tokens', 'Processed_tokens'])\n",
    "\n",
    "for submission in posts:\n",
    "    print_processing = True if posts.index(submission) <= 5 else False\n",
    "    post_description = submission.selftext\n",
    "    post_title = submission.title\n",
    "    post_title_description = post_title + \" \" + post_description\n",
    "    \n",
    "    utc_date = submission.created_utc\n",
    "    post_date = datetime.fromtimestamp(submission.created_utc).strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    unprocessed_tokens = tokeniser.tokenize(post_title_description)\n",
    "    unprocessed_token_lists.append(unprocessed_tokens)\n",
    "    \n",
    "    processed_tokens = helper.process(post_title_description, tokeniser, stemmer, stop_words, print_processing)\n",
    "    # text, tokeniser, stop_words\n",
    "    processed_token_lists.append(processed_tokens)\n",
    "    \n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments:\n",
    "        comment_text = comment.body\n",
    "        \n",
    "        unprocessed_comment_tokens = tokeniser.tokenize(comment_text)\n",
    "        unprocessed_tokens = unprocessed_tokens + unprocessed_comment_tokens\n",
    "        unprocessed_token_lists.append(unprocessed_comment_tokens)\n",
    "        \n",
    "        processed_comment_tokens = helper.process(comment_text, tokeniser, stemmer, stop_words, False)\n",
    "        processed_tokens = processed_tokens + processed_comment_tokens\n",
    "        processed_token_lists.append(processed_comment_tokens)\n",
    "    \n",
    "    if submission.author is None:\n",
    "        submission_author = 'None'\n",
    "    else:\n",
    "        submission_author = submission.author.name\n",
    "        \n",
    "    omitb_df.loc[len(omitb_df.index)] = [post_title_description, submission.num_comments, submission_author, utc_date, post_date, submission.upvote_ratio, unprocessed_tokens, processed_tokens]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e744fd492f9ecb8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(omitb_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37d30737d5fda7a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "omitb_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "696b6d4bafd26185",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "omitb_df.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46265bfc66f0caab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "post = omitb_df.loc[[0]]\n",
    "\n",
    "post"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "817fc6cd80af415",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('Post: {}\\n---------\\nAuthor: {}\\n---------\\nUpvote ratio: {}\\n---------\\nCreated date: {}\\n---------'.format(post['Post'][0], post['Author'][0], post['Upvote_ratio'][0], post['Date'][0]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b22ce57d7afd1351",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "post['Post'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9048fd8baf96842",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "post['Processed_tokens'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e788aa223133001",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1 : : Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc881d83dac84ec8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_num_posts = len(omitb_df)\n",
    "print(f'Total number of posts: {total_num_posts}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "572ec72a8e64d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_num_comments = omitb_df['Num_comments'].sum()\n",
    "print(f'Total number of comments: {total_num_comments}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6219ca15a1c46749",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_data_items = total_num_posts + total_num_comments\n",
    "print(f'Total data items: {total_data_items}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb47acd74259396b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ordered_by_date = omitb_df.sort_values(['UTC_Date'], ascending=True)\n",
    "print(f'Posts at new season announcement:\\n{ordered_by_date.head()}\\n\\n')\n",
    "print(f'Posts at season premier:\\n{ordered_by_date.tail()}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398fd41b5af50881",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per date\n",
    "num_posts_per_date = omitb_df.groupby('Date')['Post'].count()\n",
    "\n",
    "num_posts_per_date_ordered =num_posts_per_date.reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "print(f'Posts per date:\\n{num_posts_per_date_ordered.head()}')\n",
    "\n",
    "num_posts_per_date_y = num_posts_per_date.tolist()\n",
    "dates_x = omitb_df['Date'].unique().tolist()\n",
    "\n",
    "visualiser.generate_bar_chart(dates_x, num_posts_per_date_y, charles, 'Number of posts per date', 'Dates', 'Number of posts')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c6c77f10e299e4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per author\n",
    "num_posts_per_author = omitb_df.groupby('Author')['Post'].count()\n",
    "\n",
    "num_posts_per_author_ordered =num_posts_per_author.reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "print(f'Posts per author:\\n{num_posts_per_author_ordered.head()}')\n",
    "\n",
    "num_posts_per_author_y = num_posts_per_author.tolist()\n",
    "author_x = omitb_df['Author'].unique().tolist()\n",
    "\n",
    "visualiser.generate_bar_chart(author_x, num_posts_per_author_y, mabel, 'Number of posts per author', 'Author', 'Number of posts')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99fb24eb38dd80eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Comments per date\n",
    "num_comments_per_date = omitb_df.groupby('Date')['Num_comments'].sum()\n",
    "\n",
    "num_comments_per_date_ordered =num_comments_per_date.reset_index(name='sum').sort_values(['sum'], ascending=False)\n",
    "print(f'Comments per date:\\n{num_comments_per_date_ordered.head()}')\n",
    "\n",
    "num_comments_per_date_y = num_comments_per_date.tolist()\n",
    "date_x = omitb_df['Date'].unique().tolist()\n",
    "\n",
    "visualiser.generate_bar_chart(date_x, num_comments_per_date_y, mabel, 'Number of comments per date', 'Dates', 'Number of comments')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a8347a3ff6f5830",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Comments vs upvote_ratio \n",
    "num_comments_y = omitb_df['Num_comments'].tolist()\n",
    "upvote_ratio_x = omitb_df['Upvote_ratio'].tolist()\n",
    "\n",
    "visualiser.generate_scatter_plot(upvote_ratio_x, num_comments_y, charles, 'Number of comments per upvote ratio', 'Upvote Ratio', 'Number of comments')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4140dc447a424666",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Upvote_ration vs date\n",
    "upvote_ratio_per_date = omitb_df.groupby('Date')['Upvote_ratio'].count()\n",
    "\n",
    "upvote_ratio_per_date_ordered = upvote_ratio_per_date.reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "print(f'Upvote ratio per date:\\n{upvote_ratio_per_date_ordered.head()}')\n",
    "\n",
    "upvote_ratio_per_date_y = upvote_ratio_per_date.tolist()\n",
    "date_x = omitb_df['Date'].unique().tolist()\n",
    "\n",
    "visualiser.generate_bar_chart(date_x, upvote_ratio_per_date_y, oliver, 'Number of upvotes per date', 'Dates', 'Number of upvotes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acfc2dc0922a474d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b4924c8aa920ddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2 : : Pre-processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bfec205fc14f7c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "flatted_unprocessed_token_list = [element for innerList in unprocessed_token_lists for element in innerList]   \n",
    "\n",
    "helper.compute_term_freq(flatted_unprocessed_token_list, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a240e413d8c55959",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "processed_token_lists = [element for innerList in processed_token_lists for element in innerList]   \n",
    "\n",
    "helper.compute_term_freq(processed_token_lists, True, mabel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a36d2d8a3937229",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Number of unprocessed tokens: {len(flatted_unprocessed_token_list)}\\nNumber of processed tokens: {len(processed_token_lists)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608148a73555c4d6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 3 : : Models\n",
    "\n",
    "1. n-grams\n",
    "2. upvotes\n",
    "3. sentiment analysis \n",
    "    - count method\n",
    "        TODO: <sentiment / dates>\n",
    "    - vader\n",
    "        TODO: <sentiment / dates>\n",
    "4. topic modelling\n",
    "    - term doc freq\n",
    "    - TDA\n",
    "    - params\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e127a46c0ba8b737"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: n-grams "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d24e43ddf662dab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "count_sentiment_list = helper.sentiment_analysis('Count', omitb_df, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2010b2762c2d2a4b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vader_sentiment_list = helper.sentiment_analysis('Vader', omitb_df, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53072f56625fd269",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abfcb57cd428c089",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Topic modelling\n",
    "num_topic = 10\n",
    "max_word_count_to_display = 15\n",
    "num_features = 1500"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dd5cf3f4e057a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(processed_token_lists)\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26c243d36e1a137a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components =num_topic, max_iter=10, learning_method='online').fit(tf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b6d4611500b1dc0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 4 : : Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fd46fc6398415aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Present what topics are being discussed eg: top-K terms, word-cloud etc. by **topic modelling** \n",
    "2. What are the topics, does it correspond to recent news etc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5b42ad15f9bea3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "visualiser.generate_time_series(count_sentiment_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bdd29bbcdb904f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "visualiser.generate_time_series(vader_sentiment_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcf56b04e4fa276a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "visualiser.display_topics(lda_model, tf_feature_names, max_word_count_to_display)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df57437e32fdd31",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pyLDAvis\n",
    "panel = pyLDAvis.lda_model.prepare(lda_model, tf, tf_vectorizer, mds='tsne')\n",
    "\n",
    "pyLDAvis.display(panel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1da7d35ae205e32b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# wordcloud\n",
    "visualiser.display_word_cloud(lda_model, tf_feature_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dba15dd94ce959b9",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
