{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Inside the heads of Putnuts\n",
    "#### An analysis of the Only Murders in the Building TV show subreddit\n",
    "\n",
    "Milindi Kodikara"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ffc24dbff90242e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1 : : Set up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc7521a9bd0a65f2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from client import client\n",
    "import helper\n",
    "\n",
    "\n",
    "import praw\n",
    "import string\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# misc\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "from colorama import Fore, Back, Style\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8) # default plot size\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', palette='Dark2')\n",
    "from wordcloud import WordCloud"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce4026b269df7302",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subreddit_name = 'OnlyMurdersHulu'\n",
    "# maximum number of hot submissions\n",
    "# TODO: Reset to 100 for analysis\n",
    "limit = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5566865b12f59784",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reddit_client = client()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27fec5e5d6f2e7d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print('Username :: ', reddit_client.user.me())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc561188ad2d632",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subreddit = reddit_client.subreddit(subreddit_name)\n",
    "\n",
    "print('Subreddit :: ', subreddit)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bedec8775778c98",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "posts = [*subreddit.hot(limit=limit)] \n",
    "\n",
    "len(posts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc48f36a14f70818",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for submission in posts:\n",
    "    print('Title: {}\\nAuthor: {}\\nDescription: {}\\nUpvote ratio: {}\\n---------'.format(submission.title, submission.author.name, submission.selftext, submission.upvote_ratio))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74c72c986c21ad7d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "term_freq = 50\n",
    "term_freq_counter = Counter()\n",
    "\n",
    "token_list_list = []\n",
    "for submission in subreddit.hot(limit=limit):\n",
    "    post_description = submission.selftext\n",
    "    post_title = submission.title\n",
    "    \n",
    "    post_title_description = post_title + \" \" + post_description\n",
    "    \n",
    "    # text, tokeniser, stop_words\n",
    "    token_list_list.append(TweetTokenizer().tokenize(post_title_description))\n",
    "    \n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments:\n",
    "        comment_text = comment.body\n",
    "        \n",
    "        token_list_list.append(TweetTokenizer().tokenize(comment_text))\n",
    "\n",
    "flatted_list = [element for innerList in token_list_list for element in innerList]        \n",
    "term_freq_counter.update(flatted_list)\n",
    "\n",
    "\n",
    "print(\"-----------------\\nUnprocessed data term frequency\\n-----------------\\n\")\n",
    "for term, count in term_freq_counter.most_common(term_freq):\n",
    "    print(term + ': ' + str(count))\n",
    "\n",
    "y = [count for term, count in term_freq_counter.most_common(term_freq)]\n",
    "x = [term for term, count in term_freq_counter.most_common(term_freq)]\n",
    "\n",
    "# use matplotlib bar chat to plot this\n",
    "plt.bar(x, y, color='#275c4d')\n",
    "plt.title(\"Term frequency distribution\")\n",
    "plt.ylabel('# of words with term frequency')\n",
    "plt.xlabel('Term frequency')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e744fd492f9ecb8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: posts per date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c6c77f10e299e4a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: posts per user"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99fb24eb38dd80eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: comments per post"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a8347a3ff6f5830"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: comments vs upvotes "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4140dc447a424666"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: language breakdown"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c99ac53a36b55b9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: posts based on location"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80c0f17faa2f52a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Post authors' commenting freq"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acfc2dc0922a474d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b4924c8aa920ddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2 : : Pre-processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bfec205fc14f7c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Ask why use Tweet Tokenizer, why not word_tokenizer\n",
    "tokeniser = TweetTokenizer()\n",
    "# add punctuation to stopwords list\n",
    "stop_words = stopwords.words('english') + list(string.punctuation) + ['rt', 'via', '...', 'â€¦', '\"', \"'\", '`']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cb4af43c0fcaa3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tokenize and pre-process -> Add to a new dataframe to be analysed \n",
    "token_list = []\n",
    "for submission in subreddit.hot(limit=limit):\n",
    "    post_description = submission.selftext\n",
    "    post_title = submission.title\n",
    "    \n",
    "    post_title_description = post_title + \" \" + post_description\n",
    "    \n",
    "    # text, tokeniser, stop_words\n",
    "    token_list.append(helper.process(post_title_description, tokeniser, stop_words))\n",
    "    \n",
    "    comment_token_list = []\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments:\n",
    "        comment_text = comment.body\n",
    "        \n",
    "        comment_token_list.append(helper.process(comment_text, tokeniser, stop_words))\n",
    "    \n",
    "    print('Title: {}\\nAuthor: {}\\nDescription: {}\\n'.format(submission.title, submission.author.name, submission.selftext))\n",
    "    print('Token list for post: {}\\nfor comments: {} \\n-----------------\\n'.format(token_list, comment_token_list))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a240e413d8c55959",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Generate top k unigrams pre and post clean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b377bf9eb2f4ef4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Generate top k bigrams pre and post clean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "241ede2be05c74e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 3 : : Models\n",
    "\n",
    "1. n-grams\n",
    "2. upvotes\n",
    "3. sentiment analysis \n",
    "    - count method\n",
    "        TODO: <sentiment / dates>\n",
    "    - vader\n",
    "        TODO: <sentiment / dates>\n",
    "4. topic modelling\n",
    "    - term doc freq\n",
    "    - TDA\n",
    "    - params\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e127a46c0ba8b737"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sentiment_analysis = SentimentIntensityAnalyzer()\n",
    "\n",
    "# sentiment_scores = sentiment_analysis.polarity_scores(\" \".join(token_list))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2010b2762c2d2a4b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abfcb57cd428c089",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 4 : : Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fd46fc6398415aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Present what topics are being discussed eg: top-K terms, word-cloud etc. by **topic modelling** \n",
    "2. What are the topics, does it correspond to recent news etc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5b42ad15f9bea3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9df57437e32fdd31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
