{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Inside the heads of Putnuts\n",
    "#### An analysis of the Only Murders in the Building TV show subreddit\n",
    "\n",
    "Milindi Kodikara"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ffc24dbff90242e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 0 : : Set up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc7521a9bd0a65f2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from client import client\n",
    "import helper\n",
    "import charts\n",
    "\n",
    "\n",
    "import praw\n",
    "import string\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# misc\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce4026b269df7302",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subreddit_name = 'OnlyMurdersHulu'\n",
    "# maximum number of hot submissions\n",
    "# TODO: Reset to 100 for analysis\n",
    "limit = 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5566865b12f59784",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reddit_client = client()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27fec5e5d6f2e7d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print('Username :: ', reddit_client.user.me())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc561188ad2d632",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subreddit = reddit_client.subreddit(subreddit_name)\n",
    "\n",
    "print('Subreddit :: ', subreddit)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bedec8775778c98",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "posts = [*subreddit.hot(limit=limit)] \n",
    "\n",
    "len(posts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc48f36a14f70818",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "oliver = '#275c4d'\n",
    "mabel = '#af221d'\n",
    "charles = '#c59103'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28dfc294945e10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Ask why use Tweet Tokenizer, why not word_tokenizer\n",
    "tokeniser = TweetTokenizer()\n",
    "\n",
    "# add punctuation to stopwords list\n",
    "stop_words = stopwords.words('english') + list(string.punctuation) + ['rt', 'via', '...', 'â€¦', '\"', \"'\", '`', '-']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cb4af43c0fcaa3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unprocessed_token_lists = []\n",
    "processed_token_lists = []\n",
    "\n",
    "omitb_df = pd.DataFrame(columns=['Post', 'Num_comments', 'Author', 'UTC_Date', 'Date', 'Upvote_ratio', 'Unprocessed_tokens', 'Processed_tokens'])\n",
    "\n",
    "for submission in subreddit.hot(limit=limit):\n",
    "    \n",
    "    post_description = submission.selftext\n",
    "    post_title = submission.title\n",
    "    post_title_description = post_title + \" \" + post_description\n",
    "    \n",
    "    utc_date = submission.created_utc\n",
    "    post_date = datetime.fromtimestamp(submission.created_utc).strftime(\"%x\")\n",
    "    \n",
    "    unprocessed_tokens = tokeniser.tokenize(post_title_description)\n",
    "    unprocessed_token_lists.append(unprocessed_tokens)\n",
    "    \n",
    "    processed_tokens = helper.process(post_title_description, tokeniser, stop_words)\n",
    "    # text, tokeniser, stop_words\n",
    "    processed_token_lists.append(processed_tokens)\n",
    "    \n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments:\n",
    "        comment_text = comment.body\n",
    "        \n",
    "        unprocessed_comment_tokens = tokeniser.tokenize(comment_text)\n",
    "        unprocessed_tokens = unprocessed_tokens + unprocessed_comment_tokens\n",
    "        unprocessed_token_lists.append(unprocessed_comment_tokens)\n",
    "        \n",
    "        processed_comment_tokens = helper.process(comment_text, tokeniser, stop_words)\n",
    "        processed_tokens = processed_tokens + processed_comment_tokens\n",
    "        processed_token_lists.append(processed_comment_tokens)\n",
    "        \n",
    "    omitb_df.loc[len(omitb_df.index)] = [post_title_description, submission.num_comments, submission.author.name, utc_date, post_date, submission.upvote_ratio, unprocessed_tokens, processed_tokens]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e744fd492f9ecb8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "post = omitb_df.loc[[0]]\n",
    "\n",
    "post"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "817fc6cd80af415",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('Post: {}\\n---------\\nAuthor: {}\\n---------\\nUpvote ratio: {}\\n---------\\nCreated date: {}\\n---------'.format(post['Post'][0], post['Author'][0], post['Upvote_ratio'][0], post['Date'][0]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b22ce57d7afd1351",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "post['Post'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9048fd8baf96842",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "post['Processed_tokens'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e788aa223133001",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 1 : : Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc881d83dac84ec8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per date\n",
    "num_posts_per_date_y = omitb_df.groupby('Date')['Post'].count().tolist()\n",
    "dates_x = omitb_df['Date'].unique().tolist()\n",
    "\n",
    "charts.generate_bar_chart(dates_x, num_posts_per_date_y, charles, 'Number of posts per date', 'Dates', 'Number of posts')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c6c77f10e299e4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Posts per author\n",
    "num_posts_per_author_y = omitb_df.groupby('Author')['Post'].count().tolist()\n",
    "author_x = omitb_df['Author'].unique().tolist()\n",
    "\n",
    "charts.generate_bar_chart(author_x, num_posts_per_author_y, mabel, 'Number of posts per author', 'Author', 'Number of comments')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99fb24eb38dd80eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Comments per date\n",
    "num_comments_per_date_y = omitb_df.groupby('Date')['Num_comments'].sum().tolist()\n",
    "date_x = omitb_df['Date'].unique().tolist()\n",
    "\n",
    "charts.generate_bar_chart(date_x, num_comments_per_date_y, mabel, 'Number of comments per date', 'Dates', 'Number of comments')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a8347a3ff6f5830",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Comments vs upvote_ratio \n",
    "num_comments_y = omitb_df['Num_comments'].tolist()\n",
    "upvote_ratio_x = omitb_df['Upvote_ratio'].tolist()\n",
    "\n",
    "charts.generate_scatter_plot(upvote_ratio_x, num_comments_y, charles, 'Number of comments per upvote ratio', 'Upvote Ratio', 'Number of comments')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4140dc447a424666",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Upvote_ration vs date\n",
    "upvote_ratio_per_date_y = omitb_df.groupby('Date')['Upvote_ratio'].count().tolist()\n",
    "date_x = omitb_df['Date'].unique().tolist()\n",
    "\n",
    "charts.generate_bar_chart(date_x, upvote_ratio_per_date_y, oliver, 'Number of upvotes per date', 'Dates', 'Number of upvotes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acfc2dc0922a474d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b4924c8aa920ddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2 : : Pre-processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bfec205fc14f7c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "flatted_unprocessed_token_list = [element for innerList in unprocessed_token_lists for element in innerList]   \n",
    "\n",
    "helper.compute_term_freq(flatted_unprocessed_token_list, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a240e413d8c55959",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "processed_token_lists = [element for innerList in processed_token_lists for element in innerList]   \n",
    "\n",
    "helper.compute_term_freq(processed_token_lists, True, mabel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a36d2d8a3937229",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 3 : : Models\n",
    "\n",
    "1. n-grams\n",
    "2. upvotes\n",
    "3. sentiment analysis \n",
    "    - count method\n",
    "        TODO: <sentiment / dates>\n",
    "    - vader\n",
    "        TODO: <sentiment / dates>\n",
    "4. topic modelling\n",
    "    - term doc freq\n",
    "    - TDA\n",
    "    - params\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e127a46c0ba8b737"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: n-grams "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d24e43ddf662dab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "count_sentiment_list = helper.sentiment_analysis('Count', omitb_df, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2010b2762c2d2a4b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vader_sentiment_list = helper.sentiment_analysis('Vader', omitb_df, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53072f56625fd269",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abfcb57cd428c089",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Topic modelling\n",
    "num_topic = 10\n",
    "max_word_count_to_display = 15\n",
    "num_features = 1500"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dd5cf3f4e057a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(processed_token_lists)\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26c243d36e1a137a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components =num_topic, max_iter=10, learning_method='online').fit(tf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b6d4611500b1dc0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 4 : : Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fd46fc6398415aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Present what topics are being discussed eg: top-K terms, word-cloud etc. by **topic modelling** \n",
    "2. What are the topics, does it correspond to recent news etc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5b42ad15f9bea3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "charts.generate_time_series(count_sentiment_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bdd29bbcdb904f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "charts.generate_time_series(vader_sentiment_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcf56b04e4fa276a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "helper.display_topics(lda_model, tf_feature_names, max_word_count_to_display)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df57437e32fdd31",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pyLDAvis\n",
    "panel = pyLDAvis.lda_model.prepare(lda_model, tf, tf_vectorizer, mds='tsne')\n",
    "\n",
    "pyLDAvis.display(panel)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1da7d35ae205e32b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# wordcloud\n",
    "helper.display_word_cloud(lda_model, tf_feature_names)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dba15dd94ce959b9",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
